apiVersion: "v1"
kind: "ConfigMap"
metadata:
  labels:
    provider: "fabric8"
    project: "prometheus"
    version: "2.2.259"
    group: "io.fabric8.devops.apps"
  name: "prometheus"
data:
  prometheus.yml: "global:\n  scrape_interval:     5s\n  evaluation_interval: 5s\n\
    \nrule_files:\n  - \"*.rules\"\n\n# A scrape configuration for running Prometheus\
    \ on a Kubernetes cluster.\n# This uses separate scrape configs for cluster\
    \ components (i.e. API server, node)\n# and services to allow each to use different\
    \ authentication configs.\n#\n# Kubernetes labels will be added as Prometheus\
    \ labels on metrics via the\n# `labelmap` relabeling action.\nscrape_configs:\n\
    \n# Scrape config for API server.\n- job_name: 'kubernetes-apiservers'\n\n \
    \ # This TLS & bearer token file config is used to connect to the actual scrape\n\
    \  # endpoints for cluster components. This is separate to discovery auth\n\
    \  # configuration (`in_cluster` below) because discovery & scraping are two\n\
    \  # separate concerns in Prometheus.\n  tls_config:\n    # workaround for Prometheus\
    \ -> Kubernetes cert issue https://github.com/fabric8io/fabric8-devops/issues/438\n\
    \    insecure_skip_verify: true\n    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n\
    \  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\n\
    \  scheme: https\n\n  kubernetes_sd_configs:\n  - api_servers:\n    - 'https://kubernetes.default.svc'\n\
    \    in_cluster: true\n    role: apiserver\n\n  relabel_configs:\n  - action:\
    \ labelmap\n    regex: __meta_kubernetes_node_label_(.+)\n\n# Scrape config\
    \ for nodes.\n- job_name: 'kubernetes-nodes'\n\n  # This TLS & bearer token\
    \ file config is used to connect to the actual scrape\n  # endpoints for cluster\
    \ components. This is separate to discovery auth\n  # configuration (`in_cluster`\
    \ below) because discovery & scraping are two\n  # separate concerns in Prometheus.\n\
    \  tls_config:\n    # workaround for Prometheus -> Kubernetes cert issue https://github.com/fabric8io/fabric8-devops/issues/438\n\
    \    insecure_skip_verify: true\n    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n\
    \  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\n\
    \  scheme: https\n\n  kubernetes_sd_configs:\n  - api_servers:\n    - 'https://kubernetes.default.svc'\n\
    \    in_cluster: true\n    role: node\n\n  relabel_configs:\n  - action: labelmap\n\
    \    regex: __meta_kubernetes_node_label_(.+)\n\n# Scrape config for node exporter\
    \ pods deployed as a daemonset.\n- job_name: 'kubernetes-node-exporters'\n\n\
    \  kubernetes_sd_configs:\n  - api_servers:\n    - 'https://kubernetes.default.svc'\n\
    \    in_cluster: true\n    role: pod\n\n  relabel_configs:\n    - source_labels:\
    \ [__meta_kubernetes_pod_name]\n      action: keep\n      regex: node-exporter-.+\n\
    \    - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n\
    \      action: replace\n      regex: (.+):(?:\\d+);(\\d+)\n      replacement:\
    \ ${1}:${2}\n      target_label: __address__\n    - source_labels: [__meta_kubernetes_pod_node_name]\n\
    \      action: replace\n      target_label: instance\n\n# Scrape config for\
    \ service endpoints.\n#\n# The relabeling allows the actual service scrape endpoint\
    \ to be configured\n# via the following annotations:\n#\n# * `prometheus.io/scrape`:\
    \ Only scrape services that have a value of `true`\n# * `prometheus.io/scheme`:\
    \ If the metrics endpoint is secured then you will need\n# to set this to `https`\
    \ & most likely set the `tls_config` of the scrape config.\n# * `prometheus.io/path`:\
    \ If the metrics path is not `/metrics` override this.\n# * `prometheus.io/port`:\
    \ If the metrics are exposed on a different port to the\n# service then set\
    \ this appropriately.\n- job_name: 'kubernetes-service-endpoints'\n\n  kubernetes_sd_configs:\n\
    \  - api_servers:\n    - 'https://kubernetes.default.svc'\n    in_cluster: true\n\
    \    role: endpoint\n\n  relabel_configs:\n  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]\n\
    \    action: keep\n    regex: true\n  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]\n\
    \    action: replace\n    target_label: __scheme__\n    regex: (https?)\n  -\
    \ source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]\n\
    \    action: replace\n    regex: (.+)\n    target_label: __metrics_path__\n\
    \  - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]\n\
    \    action: replace\n    target_label: __address__\n    regex: (.+)(?::\\d+);(\\\
    d+)\n    replacement: $1:$2\n  - action: labelmap\n    regex: __meta_kubernetes_service_label_(.+)\n\
    \  - source_labels: [__meta_kubernetes_service_namespace]\n    action: replace\n\
    \    target_label: kubernetes_namespace\n  - source_labels: [__meta_kubernetes_service_name]\n\
    \    action: replace\n    target_label: kubernetes_name\n\n# Scrape config for\
    \ probing services via the Blackbox Exporter.\n#\n# The relabeling allows the\
    \ actual service scrape endpoint to be configured\n# via the following annotations:\n\
    #\n# * `prometheus.io/probe`: Only probe services that have a value of `true`\n\
    - job_name: 'kubernetes-services'\n\n  metrics_path: /probe\n  params:\n   \
    \ module: [http_2xx]\n\n  kubernetes_sd_configs:\n  - api_servers:\n    - 'https://kubernetes.default.svc'\n\
    \    in_cluster: true\n    role: service\n\n  relabel_configs:\n  - source_labels:\
    \ [__meta_kubernetes_service_annotation_prometheus_io_probe]\n    action: keep\n\
    \    regex: true\n  - source_labels: []\n    target_label: __address__\n   \
    \ replacement: blackbox\n  - source_labels: [__address__]\n    regex: (.*)(:80)?\n\
    \    target_label: __param_target\n  - source_labels: [__meta_kubernetes_service_name,__meta_kubernetes_service_namespace]\n\
    \    target_label: __param_target\n    regex: ([^;]+);(.+)\n    replacement:\
    \ $1.$2.svc\n  - action: labelmap\n    regex: __meta_kubernetes_service_label_(.+)\n\
    \  - source_labels: [__meta_kubernetes_service_namespace]\n    action: replace\n\
    \    target_label: kubernetes_namespace\n  - source_labels: [__meta_kubernetes_service_name]\n\
    \    action: replace\n    target_label: kubernetes_name\n\n# Scrape config for\
    \ pods\n#\n# The relabeling allows the actual pod scrape endpoint to be configured\
    \ via the\n# following annotations:\n#\n# * `prometheus.io/scrape`: Only scrape\
    \ pods that have a value of `true`\n# * `prometheus.io/port`: Scrape the pod\
    \ on the indicated port instead of the default of `9102`.\n- job_name: 'kubernetes-pods'\n\
    \n  kubernetes_sd_configs:\n  - api_servers:\n    - 'https://kubernetes.default.svc'\n\
    \    in_cluster: true\n    role: pod\n\n  relabel_configs:\n  - source_labels:\
    \ [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n    action: keep\n\
    \    regex: true\n  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]\n\
    \    action: replace\n    target_label: __scheme__\n    regex: (https?)\n  -\
    \ source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n   \
    \ action: replace\n    target_label: __metrics_path__\n    regex: (.+)\n  -\
    \ source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n\
    \    action: replace\n    regex: (.+):(?:\\d+);(\\d+)\n    replacement: ${1}:${2}\n\
    \    target_label: __address__\n  - action: labelmap\n    regex: __meta_kubernetes_pod_label_(.+)"
  pod.rules: "pod:memory_usage_bytes = sum(container_memory_usage_bytes{kubernetes_pod_name=~\"\
    .+\", job=\"kubernetes-nodes\"}) by (kubernetes_pod_name, kubernetes_namespace)\n\
    \npod:network_receive_bytes:1m = sum(rate(container_network_receive_bytes_total{kubernetes_pod_name=~\"\
    .+\", job=\"kubernetes-nodes\"}[1m])) by (kubernetes_pod_name, kubernetes_namespace)\n\
    \npod:network_transmit_bytes:1m = sum(rate(container_network_transmit_bytes_total{kubernetes_pod_name=~\"\
    .+\", job=\"kubernetes-nodes\"}[1m])) by (kubernetes_pod_name, kubernetes_namespace)\n\
    \npod:cpu_usage_seconds:1m = sum(rate(container_cpu_usage_seconds_total{kubernetes_pod_name=~\"\
    .+\", job=\"kubernetes-nodes\"}[1m])) by (kubernetes_pod_name, kubernetes_namespace)\n\
    \nALERT ServiceDown\nIF probe_success{job=\"kubernetes-services\"} == 0\n  FOR\
    \ 10s\n  LABELS {\n    service = \"{{$labels.kubernetes_namespace}}/{{$labels.kubernetes_name}}\"\
    \n  }\n  ANNOTATIONS {\n    severity    =\"page\",\n    summary     =\"Service\
    \ {{$labels.kubernetes_namespace}}/{{$labels.kubernetes_name}} down\",\n   \
    \ description =\"Service {{$labels.kubernetes_namespace}}/{{$labels.kubernetes_name}}\
    \ has been down for more than 10 seconds!\"\n  }"

# Deployment
apiVersion: "extensions/v1beta1"
kind: "Deployment"
metadata:
  annotations:
    fabric8.io/git-commit: "61631316443196f4367d519b9339b58abc99a097"
    fabric8.io/metrics-path: "dashboard/file/kubernetes-pods.json/?var-project=prometheus&var-version=2.2.259"
    fabric8.io/build-id: "1"
    fabric8.io/build-url: "http://jenkins.ux.fabric8.io/job/oss-parent/1"
    fabric8.io/iconUrl: "https://cdn.rawgit.com/fabric8io/fabric8-devops/master/prometheus/src/main/fabric8/icon.png"
    fabric8.io/git-branch: "release-v2.2.259"
    fabric8.io/git-url: "http://gogs.ux.fabric8.io/gogsadmin/oss-parent/commit/61631316443196f4367d519b9339b58abc99a097"
  labels:
    provider: "fabric8"
    project: "prometheus"
    version: "2.2.259"
    group: "io.fabric8.devops.apps"
  name: "prometheus"
spec:
  replicas: 1
  selector:
    matchLabels:
      project: "prometheus"
      provider: "fabric8"
      group: "io.fabric8.devops.apps"
  template:
    metadata:
      annotations:
        fabric8.io/git-commit: "61631316443196f4367d519b9339b58abc99a097"
        fabric8.io/metrics-path: "dashboard/file/kubernetes-pods.json/?var-project=prometheus&var-version=2.2.259"
        fabric8.io/build-id: "1"
        fabric8.io/build-url: "http://jenkins.ux.fabric8.io/job/oss-parent/1"
        fabric8.io/iconUrl: "https://cdn.rawgit.com/fabric8io/fabric8-devops/master/prometheus/src/main/fabric8/icon.png"
        fabric8.io/git-branch: "release-v2.2.259"
        fabric8.io/git-url: "http://gogs.ux.fabric8.io/gogsadmin/oss-parent/commit/61631316443196f4367d519b9339b58abc99a097"
      labels:
        provider: "fabric8"
        project: "prometheus"
        version: "2.2.259"
        group: "io.fabric8.devops.apps"
    spec:
      containers:
      - args:
        - "-config.file=/etc/prometheus/config/prometheus.yml"
        - "-storage.local.path=/prometheus"
        - "-web.console.libraries=/etc/prometheus/console_libraries"
        - "-web.console.templates=/etc/prometheus/consoles"
        image: "prom/prometheus:v1.0.1"
        livenessProbe:
          httpGet:
            port: "http"
          initialDelaySeconds: 1
        name: "prometheus"
        ports:
        - containerPort: 9090
          name: "http"
        readinessProbe:
          httpGet:
            port: "http"
          initialDelaySeconds: 1
        volumeMounts:
        - mountPath: "/etc/prometheus/config"
          name: "config-volume"
        - mountPath: "/prometheus"
          name: "data-volume"
      - args:
        - "-volume-dir"
        - "/etc/prometheus/config"
        - "-webhook-url"
        - "http://localhost:9090/-/reload"
        image: "jimmidyson/configmap-reload:v0.1"
        name: "configmap-reload"
        volumeMounts:
        - mountPath: "/etc/prometheus/config"
          name: "config-volume"
      serviceAccountName: "metrics"
      volumes:
      - configMap:
          name: "prometheus"
        name: "config-volume"
      - emptyDir: {}
        name: "data-volume"
